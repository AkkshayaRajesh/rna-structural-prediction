{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3c4ce3",
   "metadata": {},
   "source": [
    "# Step 1 – Environment & Basic Configuration\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Imports core libraries\n",
    "- Checks PyTorch version\n",
    "- Detects whether GPU (CUDA) is available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4e65e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Imports & Basic Configuration\n",
    "\n",
    "import os\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5ac82",
   "metadata": {},
   "source": [
    "# Step 2 – Data Paths & Dummy ArchiveII-Style CSV\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Defines base data directories\n",
    "- Sets up an `archiveII/processed/` folder\n",
    "- Creates a small **dummy CSV** that mimics ArchiveII format:\n",
    "  - `sequence_id`\n",
    "  - `sequence`\n",
    "  - `dot_bracket`\n",
    "\n",
    "You will later replace the dummy CSV with real processed ArchiveII data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec2d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dir: ./data\\archiveII\\processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DATA_DIR = \"./data\"\n",
    "ARCHIVEII_DIR = os.path.join(BASE_DATA_DIR, \"archiveII\")\n",
    "PROCESSED_DIR = os.path.join(ARCHIVEII_DIR, \"processed\")\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "print(\"Processed dir:\", PROCESSED_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d84cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy ArchiveII-like CSV saved to: ./data\\archiveII\\processed\\archiveII_dummy.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dot_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toy_1</td>\n",
       "      <td>GCAUCU</td>\n",
       "      <td>..(..)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toy_2</td>\n",
       "      <td>AUGCGAU</td>\n",
       "      <td>(.().).</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id sequence dot_bracket\n",
       "0       toy_1   GCAUCU      ..(..)\n",
       "1       toy_2  AUGCGAU     (.().)."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_csv_path = os.path.join(PROCESSED_DIR, \"archiveII_dummy.csv\")\n",
    "\n",
    "# Tiny toy dataset mimicking ArchiveII:\n",
    "toy_data = [\n",
    "    {\n",
    "        \"sequence_id\": \"toy_1\",\n",
    "        \"sequence\": \"GCAUCU\",\n",
    "        \"dot_bracket\": \"..(..)\"   # simple valid structure\n",
    "    },\n",
    "    {\n",
    "        \"sequence_id\": \"toy_2\",\n",
    "        \"sequence\": \"AUGCGAU\",\n",
    "        \"dot_bracket\": \"(.().).\"  # another valid structure\n",
    "    }\n",
    "]\n",
    "\n",
    "toy_df = pd.DataFrame(toy_data)\n",
    "toy_df.to_csv(dummy_csv_path, index=False)\n",
    "\n",
    "print(\"Dummy ArchiveII-like CSV saved to:\", dummy_csv_path)\n",
    "toy_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aba532",
   "metadata": {},
   "source": [
    "# Step 3 – Encoding Utilities\n",
    "\n",
    "In this notebook we implement:\n",
    "\n",
    "1. `encode_sequence(seq)` → integer IDs for A/C/G/U  \n",
    "2. `dotbracket_to_pairs(dot_bracket)` → list of base pairs `(i, j)`  \n",
    "3. `pairs_to_matrix(pairs, length)` → L × L matrix  \n",
    "4. `dotbracket_to_matrix(dot_bracket)` → convenience wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "311771ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "559b936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Encoding Utilities\n",
    "\n",
    "BASE2IDX = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "\n",
    "\n",
    "def encode_sequence(seq: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Map A/C/G/U -> 0/1/2/3.\n",
    "    Unknown bases can be mapped to 0 (A) for now.\n",
    "    \"\"\"\n",
    "    idxs = [BASE2IDX.get(b, 0) for b in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def dotbracket_to_pairs(dot_bracket: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert dot-bracket notation to a list of base pairs (i, j), 0-based.\n",
    "\n",
    "    '(' means open, ')' means close, '.' means unpaired.\n",
    "    We assume a simple non-pseudoknotted structure.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    pairs = []\n",
    "    for i, ch in enumerate(dot_bracket):\n",
    "        if ch == \"(\":\n",
    "            stack.append(i)\n",
    "        elif ch == \")\":\n",
    "            if not stack:\n",
    "                raise ValueError(f\"Unmatched closing parenthesis at position {i}\")\n",
    "            j = stack.pop()\n",
    "            # Pair (j, i)\n",
    "            pairs.append((j, i))\n",
    "        else:\n",
    "            # '.' or other unpaired symbol\n",
    "            continue\n",
    "\n",
    "    if stack:\n",
    "        raise ValueError(\"Unmatched opening parenthesis in dot-bracket string\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def pairs_to_matrix(pairs: List[Tuple[int, int]], length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Turn a list of base pairs into a symmetric L x L matrix.\n",
    "    \"\"\"\n",
    "    mat = np.zeros((length, length), dtype=np.float32)\n",
    "    for i, j in pairs:\n",
    "        if 0 <= i < length and 0 <= j < length:\n",
    "            mat[i, j] = 1.0\n",
    "            mat[j, i] = 1.0\n",
    "    return mat\n",
    "\n",
    "\n",
    "def dotbracket_to_matrix(dot_bracket: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convenience wrapper: dot-bracket -> pair list -> L x L matrix.\n",
    "    \"\"\"\n",
    "    length = len(dot_bracket)\n",
    "    pairs = dotbracket_to_pairs(dot_bracket)\n",
    "    return pairs_to_matrix(pairs, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52e5798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: GCAUCU\n",
      "Dot-bracket: ..(..)\n",
      "Encoded sequence: tensor([2, 1, 0, 3, 1, 3])\n",
      "Pair list: [(2, 5)]\n",
      "Pair matrix:\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "example_seq = \"GCAUCU\"\n",
    "example_db = \"..(..)\"\n",
    "\n",
    "print(\"Sequence:\", example_seq)\n",
    "print(\"Dot-bracket:\", example_db)\n",
    "\n",
    "encoded_seq = encode_sequence(example_seq)\n",
    "pair_list = dotbracket_to_pairs(example_db)\n",
    "pair_mat = dotbracket_to_matrix(example_db)\n",
    "\n",
    "print(\"Encoded sequence:\", encoded_seq)\n",
    "print(\"Pair list:\", pair_list)\n",
    "print(\"Pair matrix:\\n\", pair_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af57fb",
   "metadata": {},
   "source": [
    "# Step 4 – ArchiveII-Style Dataset & Collate Function\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- Defines an `ArchiveIIDataset` that reads a CSV with:\n",
    "  - `sequence_id`\n",
    "  - `sequence`\n",
    "  - `dot_bracket`\n",
    "- Uses the encoding utilities to turn dot-bracket into a base-pair matrix\n",
    "- Defines a `collate_rna_batch` function for variable-length sequences\n",
    "- Tests a small DataLoader using the **dummy CSV** from Step 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fec24",
   "metadata": {},
   "source": [
    "## Step 4: ArchiveII-style Dataset + Collate Function\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Define an `ArchiveIIDataset` class that:\n",
    "   - loads a CSV containing `sequence_id, sequence, dot_bracket`\n",
    "   - returns `(sequence_str, base_pair_matrix)` for each example  \n",
    "\n",
    "2. Define a `collate_rna_batch` function that:\n",
    "   - converts a list of `(seq_str, mat)` into:\n",
    "     - `input_ids` : (B, Lmax)\n",
    "     - `mask`      : (B, Lmax)  (True for real tokens, False for padding)\n",
    "     - `targets`   : (B, Lmax, Lmax)\n",
    "\n",
    "Here, we will only use the **dummy CSV** created earlier, but the code should work with real ArchiveII data once you generate the CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15cd9c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " ('GCAUCU', tensor([[0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0.]])))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ArchiveIIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Minimal ArchiveII-style dataset.\n",
    "\n",
    "    Expects a CSV with columns:\n",
    "      - sequence_id\n",
    "      - sequence\n",
    "      - dot_bracket\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        if not {\"sequence\", \"dot_bracket\"}.issubset(self.df.columns):\n",
    "            raise ValueError(\"CSV must contain 'sequence' and 'dot_bracket' columns\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq = row[\"sequence\"]\n",
    "        db = row[\"dot_bracket\"]\n",
    "        # Convert dot-bracket to base-pair matrix\n",
    "        mat = dotbracket_to_matrix(db)  # numpy array (L, L)\n",
    "        return seq, torch.from_numpy(mat)  # return as torch tensor\n",
    "\n",
    "\n",
    "# Instantiate dataset using the dummy CSV\n",
    "archive_dataset = ArchiveIIDataset(dummy_csv_path)\n",
    "len(archive_dataset), archive_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d200e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([2, 7])\n",
      "mask shape: torch.Size([2, 7])\n",
      "targets shape: torch.Size([2, 7, 7])\n",
      "input_ids: tensor([[2, 1, 0, 3, 1, 3, 0],\n",
      "        [0, 3, 2, 1, 2, 0, 3]])\n",
      "mask: tensor([[ True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "def collate_rna_batch(batch):\n",
    "    \"\"\"\n",
    "    Collate function for variable-length RNA sequences.\n",
    "\n",
    "    Args:\n",
    "        batch: list of (seq_str, base_pair_matrix_tensor (L, L))\n",
    "\n",
    "    Returns:\n",
    "        input_ids: (B, Lmax) int64\n",
    "        mask:      (B, Lmax) bool\n",
    "        targets:   (B, Lmax, Lmax) float32\n",
    "    \"\"\"\n",
    "    seqs, mats = zip(*batch)\n",
    "    lengths = [len(s) for s in seqs]\n",
    "    Lmax = max(lengths)\n",
    "    B = len(seqs)\n",
    "\n",
    "    input_ids = torch.zeros((B, Lmax), dtype=torch.long)\n",
    "    mask = torch.zeros((B, Lmax), dtype=torch.bool)\n",
    "    targets = torch.zeros((B, Lmax, Lmax), dtype=torch.float32)\n",
    "\n",
    "    for i, (seq, mat) in enumerate(zip(seqs, mats)):\n",
    "        L = len(seq)\n",
    "        input_ids[i, :L] = encode_sequence(seq)\n",
    "        mask[i, :L] = True\n",
    "        targets[i, :L, :L] = mat\n",
    "\n",
    "    return input_ids, mask, targets\n",
    "\n",
    "\n",
    "# Test DataLoader\n",
    "loader = DataLoader(archive_dataset, batch_size=2, shuffle=False, collate_fn=collate_rna_batch)\n",
    "\n",
    "for batch in loader:\n",
    "    input_ids, mask, targets = batch\n",
    "    print(\"input_ids shape:\", input_ids.shape)\n",
    "    print(\"mask shape:\", mask.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    print(\"input_ids:\", input_ids)\n",
    "    print(\"mask:\", mask)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76107f",
   "metadata": {},
   "source": [
    "## Step 5: Nussinov Dynamic Programming Decoder (Baseline)\n",
    "\n",
    "We implement the classical Nussinov algorithm:\n",
    "\n",
    "- For a given RNA sequence, find a structure that:\n",
    "  - obeys base-pairing rules (A–U, G–C, G–U)\n",
    "  - has no crossing pairs (no pseudoknots)\n",
    "  - maximizes the number of base pairs (or an equivalent score)\n",
    "\n",
    "This gives us a **DP baseline** and a **decoder** that we will reuse:\n",
    "\n",
    "- `nussinov_from_sequence(seq)` → dot-bracket (classical, equal score per valid pair)\n",
    "- `nussinov_from_scores(seq, score_matrix)` → dot-bracket, where `score_matrix[i,j]`\n",
    "  can come from a neural network’s base-pair probabilities/logits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-pair compatibility (Watson-Crick + wobble)\n",
    "def can_pair(b1: str, b2: str) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if two bases can form a canonical pair (A-U, G-C, G-U).\n",
    "    \"\"\"\n",
    "    pair = {b1 + b2, b2 + b1}\n",
    "    return bool(pair & {\"AU\", \"UA\", \"GC\", \"CG\", \"GU\", \"UG\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8d9d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nussinov_dp(seq: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Classical Nussinov dynamic programming (max number of base pairs).\n",
    "\n",
    "    Returns:\n",
    "        dp: 2D array of scores (L x L)\n",
    "        trace: 2D array of traceback decisions (optional / for debugging)\n",
    "    \"\"\"\n",
    "    L = len(seq)\n",
    "    dp = np.zeros((L, L), dtype=np.float32)\n",
    "\n",
    "    # Optional: store decisions if you want more detailed traceback info\n",
    "    # For simplicity, we will not store a full trace matrix here.\n",
    "\n",
    "    # Fill DP table by increasing subsequence length\n",
    "    for length in range(1, L):  # length = j - i\n",
    "        for i in range(L - length):\n",
    "            j = i + length\n",
    "            # Case 1: i unpaired\n",
    "            best = dp[i + 1, j]\n",
    "            # Case 2: j unpaired\n",
    "            best = max(best, dp[i, j - 1])\n",
    "            # Case 3: i paired with j\n",
    "            if can_pair(seq[i], seq[j]):\n",
    "                best = max(best, dp[i + 1, j - 1] + 1)\n",
    "            # Case 4: bifurcation\n",
    "            for k in range(i + 1, j):\n",
    "                best = max(best, dp[i, k] + dp[k + 1, j])\n",
    "\n",
    "            dp[i, j] = best\n",
    "\n",
    "    return dp, None  # we won't use 'trace' here\n",
    "\n",
    "\n",
    "def nussinov_traceback(seq: str, dp: np.ndarray, i: int, j: int, pairs: List[Tuple[int, int]]):\n",
    "    \"\"\"\n",
    "    Recursive traceback to recover base pairs from the DP table.\n",
    "\n",
    "    Modifies 'pairs' in place.\n",
    "    \"\"\"\n",
    "    if i >= j:\n",
    "        return\n",
    "\n",
    "    # Same logic as fill, but we compare dp entries\n",
    "    if dp[i, j] == dp[i + 1, j]:\n",
    "        nussinov_traceback(seq, dp, i + 1, j, pairs)\n",
    "    elif dp[i, j] == dp[i, j - 1]:\n",
    "        nussinov_traceback(seq, dp, i, j - 1, pairs)\n",
    "    elif can_pair(seq[i], seq[j]) and dp[i, j] == dp[i + 1, j - 1] + 1:\n",
    "        pairs.append((i, j))\n",
    "        nussinov_traceback(seq, dp, i + 1, j - 1, pairs)\n",
    "    else:\n",
    "        # bifurcation\n",
    "        for k in range(i + 1, j):\n",
    "            if dp[i, j] == dp[i, k] + dp[k + 1, j]:\n",
    "                nussinov_traceback(seq, dp, i, k, pairs)\n",
    "                nussinov_traceback(seq, dp, k + 1, j, pairs)\n",
    "                break\n",
    "\n",
    "\n",
    "def pairs_to_dotbracket(pairs: List[Tuple[int, int]], length: int) -> str:\n",
    "    \"\"\"\n",
    "    Convert a list of base pairs into dot-bracket notation.\n",
    "    \"\"\"\n",
    "    chars = [\".\"] * length\n",
    "    for i, j in pairs:\n",
    "        chars[i] = \"(\"\n",
    "        chars[j] = \")\"\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "def nussinov_from_sequence(seq: str) -> str:\n",
    "    \"\"\"\n",
    "    Run classical Nussinov on a sequence and return dot-bracket structure.\n",
    "    \"\"\"\n",
    "    L = len(seq)\n",
    "    if L == 0:\n",
    "        return \"\"\n",
    "    dp, _ = nussinov_dp(seq)\n",
    "    pairs: List[Tuple[int, int]] = []\n",
    "    nussinov_traceback(seq, dp, 0, L - 1, pairs)\n",
    "    return pairs_to_dotbracket(pairs, L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db39cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:       GCAUCU\n",
      "Pred structure: ()()..\n",
      "Pred pairs: [(0, 1), (2, 3)]\n",
      "Pred matrix:\n",
      " [[0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Test Nussinov on a simple toy sequence\n",
    "\n",
    "toy_seq = \"GCAUCU\"\n",
    "pred_db = nussinov_from_sequence(toy_seq)\n",
    "\n",
    "print(\"Sequence:      \", toy_seq)\n",
    "print(\"Pred structure:\", pred_db)\n",
    "\n",
    "# Convert predicted structure to matrix and print\n",
    "pred_pairs = dotbracket_to_pairs(pred_db) if \"(\" in pred_db or \")\" in pred_db else []\n",
    "pred_mat = pairs_to_matrix(pred_pairs, len(toy_seq))\n",
    "\n",
    "print(\"Pred pairs:\", pred_pairs)\n",
    "print(\"Pred matrix:\\n\", pred_mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f9af9",
   "metadata": {},
   "source": [
    "## ✅ Up to Step 5 Completed\n",
    "\n",
    "In this notebook, we have:\n",
    "\n",
    "1. **Project config & imports** (Step 1)\n",
    "2. **Data directory & dummy ArchiveII-style CSV** (Step 2)\n",
    "3. **Encoding utilities**:\n",
    "   - `encode_sequence`\n",
    "   - `dotbracket_to_pairs`\n",
    "   - `dotbracket_to_matrix`  (Step 3)\n",
    "4. **ArchiveIIDataset + collate function** for PyTorch (Step 4)\n",
    "5. **Nussinov DP decoder** (`nussinov_from_sequence`) as a classical baseline (Step 5)\n",
    "\n",
    "---\n",
    "\n",
    "### Next steps (beyond this notebook)\n",
    "\n",
    "- Implement `nussinov_from_scores(seq, score_matrix)` to decode neural outputs.\n",
    "- Add RNN / BiLSTM / Transformer models and plug them into this data pipeline.\n",
    "- Implement evaluation metrics (PPV, Sensitivity, F1) using predicted vs true base pairs.\n",
    "- Replace the dummy CSV with real ArchiveII / bpRNA-NF-15.0 processed files.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
