{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf5e0af",
   "metadata": {},
   "source": [
    "# RNA Structure Benchmark Preprocessing & Utilities\n",
    "\n",
    "This notebook:\n",
    "\n",
    "1. Converts **ArchiveII** `.bpseq` files → `sequence, dot_bracket` CSV  \n",
    "2. Converts **bpRNA-NF-15.0** raw CSV → the same format  \n",
    "3. Implements encoding utilities (sequence & dot-bracket)  \n",
    "4. Implements PyTorch Dataset classes + collate function  \n",
    "5. Implements Nussinov dynamic programming decoder  \n",
    "6. Runs sanity checks on both datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a425692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6331b57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook dir: c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\notebooks\n",
      "Project root: c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\n",
      "Data dir: c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# This notebook lives in project_root/notebooks\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "print(\"Notebook dir:\", NOTEBOOK_DIR)\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Data dir:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401b083",
   "metadata": {},
   "source": [
    "## 1. ArchiveII – BPSEQ → Standardized CSV\n",
    "\n",
    "We know the BPSEQ files are in:\n",
    "\n",
    "`data/archiveII/raw/archiveII_bpseq/archiveII_bpseq/`\n",
    "\n",
    "We will parse all `.bpseq` files, extract:\n",
    "\n",
    "- `sequence_id` – file name without extension  \n",
    "- `sequence` – RNA sequence (T converted to U)  \n",
    "- `dot_bracket` – structure inferred from BPSEQ pairs  \n",
    "\n",
    "and save to:\n",
    "\n",
    "`data/archiveII/processed/archiveII_from_bpseq.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a7e09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('c:/Fall_2025/CSE6301/Project/rna-structural-prediction/data/archiveII/raw/archiveII_bpseq/archiveII_bpseq'),\n",
       " WindowsPath('c:/Fall_2025/CSE6301/Project/rna-structural-prediction/data/archiveII/processed'),\n",
       " WindowsPath('c:/Fall_2025/CSE6301/Project/rna-structural-prediction/data/archiveII/processed/archiveII_from_bpseq.csv'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up ArchiveII BPSEQ paths (relative to this notebook's working directory)\n",
    "archive_bpseq_dir = DATA_DIR / \"archiveII\" / \"raw\" / \"archiveII_bpseq\" / \"archiveII_bpseq\"\n",
    "archive_processed_dir = DATA_DIR / \"archiveII\" / \"processed\"\n",
    "archive_processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "archiveii_csv_path = archive_processed_dir / \"archiveII_from_bpseq.csv\"\n",
    "\n",
    "archive_bpseq_dir, archive_processed_dir, archiveii_csv_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d89bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bpseq_file(bpseq_path: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Parse a BPSEQ file and return (sequence, dot_bracket).\n",
    "\n",
    "    BPSEQ format (typical):\n",
    "        index  base  pair_index\n",
    "    - index: 1-based position\n",
    "    - base:  single character (A,C,G,U/T,...)\n",
    "    - pair_index: 1-based index of paired position, 0 or -1 if unpaired.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    bases = []\n",
    "    partners = []\n",
    "\n",
    "    with open(bpseq_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith(\"#\") or line.startswith(\";\"):\n",
    "                continue\n",
    "\n",
    "            parts = line.split()\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            idx = int(parts[0])\n",
    "            base = parts[1]\n",
    "            pair_idx = int(parts[2])\n",
    "\n",
    "            indices.append(idx)\n",
    "            bases.append(base)\n",
    "            partners.append(pair_idx)\n",
    "\n",
    "    # sort by index just in case\n",
    "    order = sorted(range(len(indices)), key=lambda k: indices[k])\n",
    "    bases = [bases[i] for i in order]\n",
    "    partners = [partners[i] for i in order]\n",
    "\n",
    "    L = len(bases)\n",
    "\n",
    "    # Build list of base pairs (0-based)\n",
    "    pairs: List[Tuple[int, int]] = []\n",
    "    for i in range(L):\n",
    "        p = partners[i]\n",
    "        if p <= 0:\n",
    "            continue\n",
    "        j = p - 1  # convert to 0-based\n",
    "        if j > i:\n",
    "            pairs.append((i, j))\n",
    "\n",
    "    # Convert to dot-bracket\n",
    "    chars = [\".\"] * L\n",
    "    for i, j in pairs:\n",
    "        chars[i] = \"(\"\n",
    "        chars[j] = \")\"\n",
    "    dot_bracket = \"\".join(chars)\n",
    "\n",
    "    # Normalize sequence: T -> U\n",
    "    seq = \"\".join(bases).upper().replace(\"T\", \"U\")\n",
    "\n",
    "    return seq, dot_bracket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7692df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3975 BPSEQ files in c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\archiveII\\raw\\archiveII_bpseq\\archiveII_bpseq\n",
      "ArchiveII standardized CSV saved to: c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\archiveII\\processed\\archiveII_from_bpseq.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dot_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16s_A.fulgidus</td>\n",
       "      <td>AUUCUGGUUGAUCCUGCCAGAGGCCGCUGCUAUCCGGCUGGGACUA...</td>\n",
       "      <td>...(((((...(((.))))).((((((((((.((((((((((.......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16s_A.fulgidus_domain1</td>\n",
       "      <td>AUUCUGGUUGAUCCUGCCAGAGGCCGCUGCUAUCCGGCUGGGACUA...</td>\n",
       "      <td>...(((((.......))))).((((((((((.((((((((((.......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16s_A.fulgidus_domain2</td>\n",
       "      <td>UUUAUUGGGCCUAAAGCGUCCGUAGCCGGGCUGGUAAGUCCUCCGG...</td>\n",
       "      <td>.......(((((...(.((((.(.(((.(((((((.((((((((((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16s_A.fulgidus_domain3</td>\n",
       "      <td>AAGGAAUUGGCGGGGGAGCACUACAACGGGUGGAGCCUGCGGUUUA...</td>\n",
       "      <td>.......(((((.(((((((..((..((((((.((((((((((......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16s_A.fulgidus_domain4</td>\n",
       "      <td>ACCGCCCGUCAAGCCACCCGAGUGGGCCAGGGGCGAGGGGGUGGCC...</td>\n",
       "      <td>.(.(..((...((((.(((..(((((((..((((..((((((((((...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sequence_id                                           sequence  \\\n",
       "0          16s_A.fulgidus  AUUCUGGUUGAUCCUGCCAGAGGCCGCUGCUAUCCGGCUGGGACUA...   \n",
       "1  16s_A.fulgidus_domain1  AUUCUGGUUGAUCCUGCCAGAGGCCGCUGCUAUCCGGCUGGGACUA...   \n",
       "2  16s_A.fulgidus_domain2  UUUAUUGGGCCUAAAGCGUCCGUAGCCGGGCUGGUAAGUCCUCCGG...   \n",
       "3  16s_A.fulgidus_domain3  AAGGAAUUGGCGGGGGAGCACUACAACGGGUGGAGCCUGCGGUUUA...   \n",
       "4  16s_A.fulgidus_domain4  ACCGCCCGUCAAGCCACCCGAGUGGGCCAGGGGCGAGGGGGUGGCC...   \n",
       "\n",
       "                                         dot_bracket  \n",
       "0  ...(((((...(((.))))).((((((((((.((((((((((.......  \n",
       "1  ...(((((.......))))).((((((((((.((((((((((.......  \n",
       "2  .......(((((...(.((((.(.(((.(((((((.((((((((((...  \n",
       "3  .......(((((.(((((((..((..((((((.((((((((((......  \n",
       "4  .(.(..((...((((.(((..(((((((..((((..((((((((((...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpseq_files = list(archive_bpseq_dir.glob(\"*.bpseq\"))\n",
    "print(f\"Found {len(bpseq_files)} BPSEQ files in {archive_bpseq_dir}\")\n",
    "\n",
    "archive_records = []\n",
    "\n",
    "for path in bpseq_files:\n",
    "    fname = path.name\n",
    "    seq_id = os.path.splitext(fname)[0]\n",
    "\n",
    "    seq, db = parse_bpseq_file(path)\n",
    "\n",
    "    if len(seq) != len(db):\n",
    "        print(\n",
    "            f\"WARNING: length mismatch in {fname}: \"\n",
    "            f\"len(seq)={len(seq)}, len(dot_bracket)={len(db)}\"\n",
    "        )\n",
    "\n",
    "    archive_records.append(\n",
    "        {\n",
    "            \"sequence_id\": seq_id,\n",
    "            \"sequence\": seq,\n",
    "            \"dot_bracket\": db,\n",
    "        }\n",
    "    )\n",
    "\n",
    "archiveii_df = pd.DataFrame(archive_records)\n",
    "archiveii_df.to_csv(archiveii_csv_path, index=False)\n",
    "\n",
    "print(\"ArchiveII standardized CSV saved to:\", archiveii_csv_path)\n",
    "archiveii_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1bfbe2",
   "metadata": {},
   "source": [
    "## 2. bpRNA-NF-15.0 – Raw CSV → Standardized CSV\n",
    "\n",
    "Raw file path (you may have both absolute and relative):\n",
    "\n",
    "- Absolute (Windows, from your system):  \n",
    "  `C:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\bprna_nf15\\raw\\bpRNA-NF-15.0.csv`\n",
    "\n",
    "We’ll also define a **relative path** so the notebook is portable:\n",
    "\n",
    "`data/bprna_nf15/raw/bpRNA-NF-15.0.csv`\n",
    "\n",
    "We will inspect its columns, then map:\n",
    "\n",
    "- `sequence_id`\n",
    "- `sequence`\n",
    "- `dot_bracket`\n",
    "\n",
    "into:\n",
    "\n",
    "`data/bprna_nf15/processed/bprna_nf15_standardized.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8ebc9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('c:/Fall_2025/CSE6301/Project/rna-structural-prediction/data/bprna_nf15/raw/bpRNA-NF-15.0.csv'),\n",
       " WindowsPath('c:/Fall_2025/CSE6301/Project/rna-structural-prediction/data/bprna_nf15/processed/bprna_nf15_standardized.csv'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative to project root (data is sibling of notebooks)\n",
    "bprna_raw_csv = DATA_DIR / \"bprna_nf15\" / \"raw\" / \"bpRNA-NF-15.0.csv\"\n",
    "\n",
    "bprna_processed_dir = DATA_DIR / \"bprna_nf15\" / \"processed\"\n",
    "bprna_processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "bprna_processed_csv = bprna_processed_dir / \"bprna_nf15_standardized.csv\"\n",
    "\n",
    "bprna_raw_csv, bprna_processed_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1ac1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpRNA-NF-15.0 raw shape: (8788, 3)\n",
      "Columns: ['rna_name', 'seq', 'struct']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rna_name</th>\n",
       "      <th>seq</th>\n",
       "      <th>struct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP002582.1/3780440-3780356</td>\n",
       "      <td>UUAAUGAGAAUAAAUCAGGUUAUUAUGUUGGAUGUAAUAACUGGGC...</td>\n",
       "      <td>.........[[[...[.((((((((((.....))))))))))..((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP001997.1/495019-495096</td>\n",
       "      <td>UCCUUACAAGAUCAGGCGGCUUUUAGUGCGGCCGGGCCUCUUUUGA...</td>\n",
       "      <td>.......[[[..[.(((.((.....))...)))..(((((....))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP002028.1/1768652-1768573</td>\n",
       "      <td>AAAGCAUAAUGGAUCAGGUAGAACGGAAAAGUUUUACCGGGCUCUU...</td>\n",
       "      <td>........[[[[..[.((((((((......))))))))..((((.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAWL01000017.1/25112-25035</td>\n",
       "      <td>AUAAUACAACAGGAACAGGCGGCUGCCGCGAGGCAGUGCAGCCGGG...</td>\n",
       "      <td>.........[[[[..[.(((.((((((....))))))...)))..(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADLR01000090.1/3100-3003</td>\n",
       "      <td>AUAUGAUACAGUGAGCAGGCGACGGCCGAAAUGAGAAUCGUCGCCG...</td>\n",
       "      <td>.........[.[[..[.((((((((............))))))))....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rna_name  \\\n",
       "0  CP002582.1/3780440-3780356   \n",
       "1    CP001997.1/495019-495096   \n",
       "2  CP002028.1/1768652-1768573   \n",
       "3  AAWL01000017.1/25112-25035   \n",
       "4    ADLR01000090.1/3100-3003   \n",
       "\n",
       "                                                 seq  \\\n",
       "0  UUAAUGAGAAUAAAUCAGGUUAUUAUGUUGGAUGUAAUAACUGGGC...   \n",
       "1  UCCUUACAAGAUCAGGCGGCUUUUAGUGCGGCCGGGCCUCUUUUGA...   \n",
       "2  AAAGCAUAAUGGAUCAGGUAGAACGGAAAAGUUUUACCGGGCUCUU...   \n",
       "3  AUAAUACAACAGGAACAGGCGGCUGCCGCGAGGCAGUGCAGCCGGG...   \n",
       "4  AUAUGAUACAGUGAGCAGGCGACGGCCGAAAUGAGAAUCGUCGCCG...   \n",
       "\n",
       "                                              struct  \n",
       "0  .........[[[...[.((((((((((.....))))))))))..((...  \n",
       "1  .......[[[..[.(((.((.....))...)))..(((((....))...  \n",
       "2  ........[[[[..[.((((((((......))))))))..((((.....  \n",
       "3  .........[[[[..[.(((.((((((....))))))...)))..(...  \n",
       "4  .........[.[[..[.((((((((............))))))))....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bprna_df_raw = pd.read_csv(bprna_raw_csv)\n",
    "\n",
    "print(\"bpRNA-NF-15.0 raw shape:\", bprna_df_raw.shape)\n",
    "print(\"Columns:\", list(bprna_df_raw.columns))\n",
    "bprna_df_raw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0777049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized bpRNA shape: (8788, 3)\n",
      "Length mismatches: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>dot_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CP002582.1/3780440-3780356</td>\n",
       "      <td>UUAAUGAGAAUAAAUCAGGUUAUUAUGUUGGAUGUAAUAACUGGGC...</td>\n",
       "      <td>.........[[[...[.((((((((((.....))))))))))..((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CP001997.1/495019-495096</td>\n",
       "      <td>UCCUUACAAGAUCAGGCGGCUUUUAGUGCGGCCGGGCCUCUUUUGA...</td>\n",
       "      <td>.......[[[..[.(((.((.....))...)))..(((((....))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CP002028.1/1768652-1768573</td>\n",
       "      <td>AAAGCAUAAUGGAUCAGGUAGAACGGAAAAGUUUUACCGGGCUCUU...</td>\n",
       "      <td>........[[[[..[.((((((((......))))))))..((((.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAWL01000017.1/25112-25035</td>\n",
       "      <td>AUAAUACAACAGGAACAGGCGGCUGCCGCGAGGCAGUGCAGCCGGG...</td>\n",
       "      <td>.........[[[[..[.(((.((((((....))))))...)))..(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADLR01000090.1/3100-3003</td>\n",
       "      <td>AUAUGAUACAGUGAGCAGGCGACGGCCGAAAUGAGAAUCGUCGCCG...</td>\n",
       "      <td>.........[.[[..[.((((((((............))))))))....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sequence_id  \\\n",
       "0  CP002582.1/3780440-3780356   \n",
       "1    CP001997.1/495019-495096   \n",
       "2  CP002028.1/1768652-1768573   \n",
       "3  AAWL01000017.1/25112-25035   \n",
       "4    ADLR01000090.1/3100-3003   \n",
       "\n",
       "                                            sequence  \\\n",
       "0  UUAAUGAGAAUAAAUCAGGUUAUUAUGUUGGAUGUAAUAACUGGGC...   \n",
       "1  UCCUUACAAGAUCAGGCGGCUUUUAGUGCGGCCGGGCCUCUUUUGA...   \n",
       "2  AAAGCAUAAUGGAUCAGGUAGAACGGAAAAGUUUUACCGGGCUCUU...   \n",
       "3  AUAAUACAACAGGAACAGGCGGCUGCCGCGAGGCAGUGCAGCCGGG...   \n",
       "4  AUAUGAUACAGUGAGCAGGCGACGGCCGAAAUGAGAAUCGUCGCCG...   \n",
       "\n",
       "                                         dot_bracket  \n",
       "0  .........[[[...[.((((((((((.....))))))))))..((...  \n",
       "1  .......[[[..[.(((.((.....))...)))..(((((....))...  \n",
       "2  ........[[[[..[.((((((((......))))))))..((((.....  \n",
       "3  .........[[[[..[.(((.((((((....))))))...)))..(...  \n",
       "4  .........[.[[..[.((((((((............))))))))....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: adjust these three names to match actual column names in bpRNA-NF-15.0.csv\n",
    "# Common patterns: 'sequence', 'str', 'structure', 'dot_bracket', etc.\n",
    "seq_col = \"seq\"   # <-- change if different\n",
    "db_col = \"struct\"   # <-- change if different\n",
    "id_col = \"rna_name\"          # <-- change if different; or we create synthetic IDs\n",
    "\n",
    "# If the ID column doesn't exist, create a synthetic one\n",
    "if id_col not in bprna_df_raw.columns:\n",
    "    print(f\"Column '{id_col}' not found; creating synthetic sequence_id.\")\n",
    "    bprna_df_raw[\"sequence_id\"] = [f\"bprna_{i}\" for i in range(len(bprna_df_raw))]\n",
    "    id_col = \"sequence_id\"\n",
    "\n",
    "# Normalize sequences: T -> U\n",
    "bprna_df_raw[seq_col] = bprna_df_raw[seq_col].astype(str).str.upper().str.replace(\"T\", \"U\")\n",
    "\n",
    "bprna_df = pd.DataFrame(\n",
    "    {\n",
    "        \"sequence_id\": bprna_df_raw[id_col].astype(str),\n",
    "        \"sequence\": bprna_df_raw[seq_col].astype(str),\n",
    "        \"dot_bracket\": bprna_df_raw[db_col].astype(str),\n",
    "    }\n",
    ")\n",
    "\n",
    "len_mismatch = (bprna_df[\"sequence\"].str.len() != bprna_df[\"dot_bracket\"].str.len()).sum()\n",
    "print(\"Standardized bpRNA shape:\", bprna_df.shape)\n",
    "print(\"Length mismatches:\", len_mismatch)\n",
    "\n",
    "bprna_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d073eac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized bpRNA CSV saved to: c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\bprna_nf15\\processed\\bprna_nf15_standardized.csv\n"
     ]
    }
   ],
   "source": [
    "bprna_df.to_csv(bprna_processed_csv, index=False)\n",
    "print(\"Standardized bpRNA CSV saved to:\", bprna_processed_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c5155",
   "metadata": {},
   "source": [
    "## 3. Encoding Utilities\n",
    "\n",
    "We now define:\n",
    "\n",
    "- `encode_sequence(seq)` → integer IDs (A/C/G/U)\n",
    "- `dotbracket_to_pairs(dot_bracket)` → list of base pairs\n",
    "- `pairs_to_matrix(pairs, length)` → L×L numpy matrix\n",
    "- `dotbracket_to_matrix(dot_bracket)` → convenience wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb838c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic RNA vocabulary\n",
    "BASE2IDX = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "\n",
    "\n",
    "def encode_sequence(seq: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Encode an RNA sequence to integer IDs.\n",
    "    - Upper-case\n",
    "    - Convert T->U\n",
    "    - Unknown bases -> 0 (A)\n",
    "    \"\"\"\n",
    "    seq = seq.upper().replace(\"T\", \"U\")\n",
    "    idxs = [BASE2IDX.get(b, 0) for b in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "def dotbracket_to_pairs(dot_bracket: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Convert dot-bracket string to base-pair list (i, j), 0-based.\n",
    "    Assumes non-pseudoknotted structures using '(' and ')'.\n",
    "    \"\"\"\n",
    "    stack = []\n",
    "    pairs = []\n",
    "    for i, ch in enumerate(dot_bracket):\n",
    "        if ch == \"(\":\n",
    "            stack.append(i)\n",
    "        elif ch == \")\":\n",
    "            if not stack:\n",
    "                raise ValueError(f\"Unmatched ')' at position {i} in {dot_bracket}\")\n",
    "            j = stack.pop()\n",
    "            pairs.append((j, i))\n",
    "        # '.' etc. = unpaired\n",
    "\n",
    "    if stack:\n",
    "        raise ValueError(f\"Unmatched '(' in dot-bracket: {dot_bracket}\")\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def pairs_to_matrix(pairs: List[Tuple[int, int]], length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert base-pair list to symmetric L×L matrix.\n",
    "    \"\"\"\n",
    "    mat = np.zeros((length, length), dtype=np.float32)\n",
    "    for i, j in pairs:\n",
    "        if 0 <= i < length and 0 <= j < length:\n",
    "            mat[i, j] = 1.0\n",
    "            mat[j, i] = 1.0\n",
    "    return mat\n",
    "\n",
    "\n",
    "def dotbracket_to_matrix(dot_bracket: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    dot-bracket → base-pair list → L×L matrix\n",
    "    \"\"\"\n",
    "    L = len(dot_bracket)\n",
    "    pairs = dotbracket_to_pairs(dot_bracket)\n",
    "    return pairs_to_matrix(pairs, L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bef37616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence: GCAUCU\n",
      "Dot-bracket: ..(..)\n",
      "Encoded: tensor([2, 1, 0, 3, 1, 3])\n",
      "Pairs: [(2, 5)]\n",
      "Matrix:\n",
      " [[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "seq_test = \"GCAUCU\"\n",
    "db_test = \"..(..)\"\n",
    "\n",
    "print(\"Sequence:\", seq_test)\n",
    "print(\"Dot-bracket:\", db_test)\n",
    "\n",
    "encoded = encode_sequence(seq_test)\n",
    "pairs = dotbracket_to_pairs(db_test)\n",
    "mat = dotbracket_to_matrix(db_test)\n",
    "\n",
    "print(\"Encoded:\", encoded)\n",
    "print(\"Pairs:\", pairs)\n",
    "print(\"Matrix:\\n\", mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f056d73",
   "metadata": {},
   "source": [
    "## 4. PyTorch Datasets and Collate Function\n",
    "\n",
    "We define:\n",
    "\n",
    "- `ArchiveIIDataset` – loads `archiveII_from_bpseq.csv`\n",
    "- `BpRNANFDataset` – loads `bprna_nf15_standardized.csv`\n",
    "- `collate_rna_batch` – pads sequences and matrices into batched tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ab5e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArchiveIIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ArchiveII dataset from standardized CSV with columns:\n",
    "      - sequence_id\n",
    "      - sequence\n",
    "      - dot_bracket\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = csv_path\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        required = {\"sequence\", \"dot_bracket\"}\n",
    "        if not required.issubset(self.df.columns):\n",
    "            raise ValueError(f\"Missing required columns {required} in {csv_path}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq = str(row[\"sequence\"])\n",
    "        db = str(row[\"dot_bracket\"])\n",
    "        mat = torch.from_numpy(dotbracket_to_matrix(db))  # (L, L)\n",
    "        return seq, mat\n",
    "\n",
    "\n",
    "class BpRNANFDataset(Dataset):\n",
    "    \"\"\"\n",
    "    bpRNA-NF-15.0 dataset from standardized CSV with columns:\n",
    "      - sequence_id\n",
    "      - sequence\n",
    "      - dot_bracket\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path: str):\n",
    "        self.csv_path = csv_path\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        required = {\"sequence\", \"dot_bracket\"}\n",
    "        if not required.issubset(self.df.columns):\n",
    "            raise ValueError(f\"Missing required columns {required} in {csv_path}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq = str(row[\"sequence\"])\n",
    "        db = str(row[\"dot_bracket\"])\n",
    "        mat = torch.from_numpy(dotbracket_to_matrix(db))\n",
    "        return seq, mat\n",
    "\n",
    "\n",
    "def collate_rna_batch(batch):\n",
    "    \"\"\"\n",
    "    Collate function for variable-length RNA sequences.\n",
    "\n",
    "    batch: list of (sequence_str, basepair_matrix_tensor (L, L))\n",
    "\n",
    "    Returns:\n",
    "      input_ids: (B, Lmax) int64\n",
    "      mask:      (B, Lmax) bool (True = valid token)\n",
    "      targets:   (B, Lmax, Lmax) float32\n",
    "    \"\"\"\n",
    "    seqs, mats = zip(*batch)\n",
    "    lengths = [len(s) for s in seqs]\n",
    "    Lmax = max(lengths)\n",
    "    B = len(seqs)\n",
    "\n",
    "    input_ids = torch.zeros((B, Lmax), dtype=torch.long)\n",
    "    mask = torch.zeros((B, Lmax), dtype=torch.bool)\n",
    "    targets = torch.zeros((B, Lmax, Lmax), dtype=torch.float32)\n",
    "\n",
    "    for i, (seq, mat) in enumerate(zip(seqs, mats)):\n",
    "        L = len(seq)\n",
    "        input_ids[i, :L] = encode_sequence(seq)\n",
    "        mask[i, :L] = True\n",
    "        targets[i, :L, :L] = mat\n",
    "\n",
    "    return input_ids, mask, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036ac817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArchiveII dataset size: 3975\n",
      "bpRNA dataset size: 8788\n",
      "input_ids shape: torch.Size([4, 342])\n",
      "mask shape: torch.Size([4, 342])\n",
      "targets shape: torch.Size([4, 342, 342])\n"
     ]
    }
   ],
   "source": [
    "# Paths to standardized CSVs we created earlier\n",
    "archiveii_csv_path = archiveii_csv_path  # from Cell 4\n",
    "bprna_processed_csv = bprna_processed_csv  # from Cell 8/11\n",
    "\n",
    "arch_dataset = ArchiveIIDataset(archiveii_csv_path)\n",
    "bprna_dataset = BpRNANFDataset(bprna_processed_csv)\n",
    "\n",
    "print(\"ArchiveII dataset size:\", len(arch_dataset))\n",
    "print(\"bpRNA dataset size:\", len(bprna_dataset))\n",
    "\n",
    "arch_loader = DataLoader(arch_dataset, batch_size=4, shuffle=True, collate_fn=collate_rna_batch)\n",
    "\n",
    "input_ids, mask, targets = next(iter(arch_loader))\n",
    "print(\"input_ids shape:\", input_ids.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "print(\"targets shape:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "222ab1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total = 3975, length <= 400 = 3685\n",
      "Randomly sampled 200 indices for evaluation.\n",
      "Total = 8788, length <= 400 = 8624\n",
      "Randomly sampled 200 indices for evaluation.\n",
      "ArchiveII eval subset size: 200\n",
      "bpRNA eval subset size: 200\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# For reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "def make_eval_subset(dataset, max_len=400, max_n=200):\n",
    "    \"\"\"\n",
    "    Filter dataset by sequence length and randomly sample at most max_n examples.\n",
    "\n",
    "    Args:\n",
    "      dataset: ArchiveIIDataset or BpRNANFDataset\n",
    "      max_len: maximum sequence length allowed\n",
    "      max_n:   maximum number of sequences to keep\n",
    "\n",
    "    Returns:\n",
    "      subset: torch.utils.data.Subset\n",
    "    \"\"\"\n",
    "    # 1. Filter by length\n",
    "    filtered_indices = [\n",
    "        i for i in range(len(dataset))\n",
    "        if len(dataset[i][0]) <= max_len\n",
    "    ]\n",
    "    print(f\"Total = {len(dataset)}, length <= {max_len} = {len(filtered_indices)}\")\n",
    "\n",
    "    # 2. Randomly sample at most max_n\n",
    "    if len(filtered_indices) > max_n:\n",
    "        filtered_indices = random.sample(filtered_indices, max_n)\n",
    "        print(f\"Randomly sampled {max_n} indices for evaluation.\")\n",
    "    else:\n",
    "        print(\"Using all filtered sequences (no subsampling).\")\n",
    "\n",
    "    subset = torch.utils.data.Subset(dataset, filtered_indices)\n",
    "    return subset\n",
    "\n",
    "\n",
    "# You can tweak these depending on runtime\n",
    "ARCH_MAX_LEN = 400\n",
    "ARCH_MAX_N   = 200\n",
    "\n",
    "BPRNA_MAX_LEN = 400\n",
    "BPRNA_MAX_N   = 200\n",
    "\n",
    "arch_eval_subset = make_eval_subset(arch_dataset, max_len=ARCH_MAX_LEN, max_n=ARCH_MAX_N)\n",
    "bprna_eval_subset = make_eval_subset(bprna_dataset, max_len=BPRNA_MAX_LEN, max_n=BPRNA_MAX_N)\n",
    "\n",
    "print(\"ArchiveII eval subset size:\", len(arch_eval_subset))\n",
    "print(\"bpRNA eval subset size:\", len(bprna_eval_subset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7244462b",
   "metadata": {},
   "source": [
    "## 5. Nussinov Dynamic Programming Decoder\n",
    "\n",
    "We implement:\n",
    "\n",
    "- `nussinov_from_sequence(seq)` – classic DP maximizing number of base pairs  \n",
    "- `nussinov_from_scores(seq, score_matrix)` – future use with neural model scores  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c45fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def can_pair(b1: str, b2: str) -> bool:\n",
    "    \"\"\"\n",
    "    Canonical base-pairing rules (Watson-Crick + wobble).\n",
    "    \"\"\"\n",
    "    pair = {b1 + b2, b2 + b1}\n",
    "    return bool(pair & {\"AU\", \"UA\", \"GC\", \"CG\", \"GU\", \"UG\"})\n",
    "\n",
    "\n",
    "def nussinov_dp(seq: str, scores: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Nussinov DP to maximize total pairing score.\n",
    "\n",
    "    If scores is None, each valid pair scores 1.0.\n",
    "    Otherwise, scores[i, j] is used for base pair (i, j).\n",
    "    \"\"\"\n",
    "    L = len(seq)\n",
    "    dp = np.zeros((L, L), dtype=np.float32)\n",
    "\n",
    "    for length in range(1, L):  # j - i\n",
    "        for i in range(L - length):\n",
    "            j = i + length\n",
    "\n",
    "            # Case 1: i unpaired\n",
    "            best = dp[i + 1, j]\n",
    "\n",
    "            # Case 2: j unpaired\n",
    "            best = max(best, dp[i, j - 1])\n",
    "\n",
    "            # Case 3: i paired with j\n",
    "            if can_pair(seq[i], seq[j]):\n",
    "                pair_score = 1.0 if scores is None else scores[i, j]\n",
    "                best = max(best, dp[i + 1, j - 1] + pair_score)\n",
    "\n",
    "            # Case 4: bifurcation\n",
    "            for k in range(i + 1, j):\n",
    "                best = max(best, dp[i, k] + dp[k + 1, j])\n",
    "\n",
    "            dp[i, j] = best\n",
    "\n",
    "    return dp\n",
    "\n",
    "\n",
    "def nussinov_traceback(\n",
    "    seq: str, dp: np.ndarray, scores: np.ndarray | None, i: int, j: int, pairs: List[Tuple[int, int]]\n",
    "):\n",
    "    \"\"\"\n",
    "    Traceback to recover optimal base pairs from DP table.\n",
    "    \"\"\"\n",
    "    if i >= j:\n",
    "        return\n",
    "\n",
    "    if dp[i, j] == dp[i + 1, j]:\n",
    "        nussinov_traceback(seq, dp, scores, i + 1, j, pairs)\n",
    "    elif dp[i, j] == dp[i, j - 1]:\n",
    "        nussinov_traceback(seq, dp, scores, i, j - 1, pairs)\n",
    "    elif can_pair(seq[i], seq[j]):\n",
    "        pair_score = 1.0 if scores is None else scores[i, j]\n",
    "        if dp[i, j] == dp[i + 1, j - 1] + pair_score:\n",
    "            pairs.append((i, j))\n",
    "            nussinov_traceback(seq, dp, scores, i + 1, j - 1, pairs)\n",
    "        else:\n",
    "            for k in range(i + 1, j):\n",
    "                if dp[i, j] == dp[i, k] + dp[k + 1, j]:\n",
    "                    nussinov_traceback(seq, dp, scores, i, k, pairs)\n",
    "                    nussinov_traceback(seq, dp, scores, k + 1, j, pairs)\n",
    "                    break\n",
    "    else:\n",
    "        for k in range(i + 1, j):\n",
    "            if dp[i, j] == dp[i, k] + dp[k + 1, j]:\n",
    "                nussinov_traceback(seq, dp, scores, i, k, pairs)\n",
    "                nussinov_traceback(seq, dp, scores, k + 1, j, pairs)\n",
    "                break\n",
    "\n",
    "\n",
    "def pairs_to_dotbracket(pairs: List[Tuple[int, int]], length: int) -> str:\n",
    "    chars = [\".\"] * length\n",
    "    for i, j in pairs:\n",
    "        chars[i] = \"(\"\n",
    "        chars[j] = \")\"\n",
    "    return \"\".join(chars)\n",
    "\n",
    "\n",
    "def nussinov_from_sequence(seq: str) -> str:\n",
    "    \"\"\"\n",
    "    Classic Nussinov: each valid base pair = 1.\n",
    "    \"\"\"\n",
    "    L = len(seq)\n",
    "    if L == 0:\n",
    "        return \"\"\n",
    "    dp = nussinov_dp(seq, scores=None)\n",
    "    pairs: List[Tuple[int, int]] = []\n",
    "    nussinov_traceback(seq, dp, scores=None, i=0, j=L - 1, pairs=pairs)\n",
    "    return pairs_to_dotbracket(pairs, L)\n",
    "\n",
    "\n",
    "def nussinov_from_scores(seq: str, score_matrix: np.ndarray) -> str:\n",
    "    \"\"\"\n",
    "    Nussinov decoding using model-provided score matrix.\n",
    "    \"\"\"\n",
    "    L = len(seq)\n",
    "    assert score_matrix.shape == (L, L)\n",
    "    dp = nussinov_dp(seq, scores=score_matrix)\n",
    "    pairs: List[Tuple[int, int]] = []\n",
    "    nussinov_traceback(seq, dp, scores=score_matrix, i=0, j=L - 1, pairs=pairs)\n",
    "    return pairs_to_dotbracket(pairs, L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8efc9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence ID 0 length: 1492\n",
      "Sequence 0: AUUCUGGUUGAUCCUGCCAGAGGCCGCUGCUAUCCGGCUGGGACUAAGCCAUGCGAGUCAAGGGGCUUGUAUCCCUUCGG...\n",
      "Nussinov predicted structure (first 80 chars): .(((())(())((((()(.)((()()))()(()(())(())(((().()(()()).))))))))()((((()(((((())...\n",
      "True matrix shape: torch.Size([1492, 1492])\n",
      "Pred matrix shape: (1492, 1492)\n"
     ]
    }
   ],
   "source": [
    "# Take first ArchiveII sequence and run Nussinov baseline\n",
    "seq0, true_mat0 = arch_dataset[0]\n",
    "pred_db0 = nussinov_from_sequence(seq0)\n",
    "\n",
    "print(\"Sequence ID 0 length:\", len(seq0))\n",
    "print(\"Sequence 0:\", seq0[:80] + (\"...\" if len(seq0) > 80 else \"\"))\n",
    "print(\"Nussinov predicted structure (first 80 chars):\", pred_db0[:80] + (\"...\" if len(pred_db0) > 80 else \"\"))\n",
    "\n",
    "# Compare predicted structure matrix with true matrix shape\n",
    "pred_pairs0 = dotbracket_to_pairs(pred_db0)\n",
    "pred_mat0 = pairs_to_matrix(pred_pairs0, len(seq0))\n",
    "\n",
    "print(\"True matrix shape:\", true_mat0.shape)\n",
    "print(\"Pred matrix shape:\", pred_mat0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb78c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pair_matrices(true_mat, pred_mat):\n",
    "    \"\"\"\n",
    "    Computes pair-level TP, FP, FN, Precision, Recall, F1.\n",
    "\n",
    "    Inputs:\n",
    "      true_mat: torch.Tensor or numpy array (L, L)\n",
    "      pred_mat: same shape\n",
    "\n",
    "    Returns:\n",
    "      dictionary of metrics\n",
    "    \"\"\"\n",
    "    # Convert to torch tensors\n",
    "    if not isinstance(true_mat, torch.Tensor):\n",
    "        true_mat = torch.tensor(true_mat)\n",
    "    if not isinstance(pred_mat, torch.Tensor):\n",
    "        pred_mat = torch.tensor(pred_mat)\n",
    "\n",
    "    # Only upper triangle is needed (avoid counting (i,j) and (j,i) twice)\n",
    "    triu = torch.triu(torch.ones_like(true_mat), diagonal=1).bool()\n",
    "\n",
    "    true_pairs = true_mat.bool() & triu\n",
    "    pred_pairs = pred_mat.bool() & triu\n",
    "\n",
    "    TP = (true_pairs & pred_pairs).sum().item()\n",
    "    FP = ((~true_pairs) & pred_pairs).sum().item()\n",
    "    FN = (true_pairs & (~pred_pairs)).sum().item()\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1        = 2*TP / (2*TP + FP + FN) if (2*TP + FP + FN) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"TP\": TP,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7aa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nussinov_eval_on_subset(subset, name=\"dataset\"):\n",
    "    \"\"\"\n",
    "    Run Nussinov on every sequence in the given subset and collect metrics.\n",
    "\n",
    "    subset: torch.utils.data.Subset (or any Dataset with __getitem__ -> (seq, true_mat))\n",
    "    name:   label for logging\n",
    "\n",
    "    Returns:\n",
    "      metrics_df: pandas DataFrame with one row per sequence\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    n = len(subset)\n",
    "    print(f\"Running Nussinov on {n} sequences from {name}...\")\n",
    "\n",
    "    for i in range(n):\n",
    "        seq, true_mat = subset[i]   # seq: str, true_mat: torch.Tensor (L, L)\n",
    "        L = len(seq)\n",
    "\n",
    "        # Run Nussinov\n",
    "        pred_db = nussinov_from_sequence(seq)\n",
    "        pred_pairs = dotbracket_to_pairs(pred_db) if \"(\" in pred_db or \")\" in pred_db else []\n",
    "        pred_mat = pairs_to_matrix(pred_pairs, L)\n",
    "        pred_mat_t = torch.tensor(pred_mat, dtype=torch.float32)\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compare_pair_matrices(true_mat, pred_mat_t)\n",
    "        metrics[\"seq_len\"] = L\n",
    "        metrics[\"index\"] = i\n",
    "\n",
    "        records.append(metrics)\n",
    "\n",
    "        if (i + 1) % 20 == 0 or (i + 1) == n:\n",
    "            print(f\"  Done {i+1}/{n}\")\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    print(f\"\\n{name} Nussinov summary:\")\n",
    "    print(df[[\"Precision\", \"Recall\", \"F1\"]].describe())\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e97e9558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Nussinov on 200 sequences from ArchiveII...\n",
      "  Done 20/200\n",
      "  Done 40/200\n",
      "  Done 60/200\n",
      "  Done 80/200\n",
      "  Done 100/200\n",
      "  Done 120/200\n",
      "  Done 140/200\n",
      "  Done 160/200\n",
      "  Done 180/200\n",
      "  Done 200/200\n",
      "\n",
      "ArchiveII Nussinov summary:\n",
      "        Precision      Recall          F1\n",
      "count  200.000000  200.000000  200.000000\n",
      "mean     0.032028    0.052749    0.039553\n",
      "std      0.057043    0.094773    0.070494\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000\n",
      "50%      0.000000    0.000000    0.000000\n",
      "75%      0.042052    0.076406    0.052731\n",
      "max      0.317073    0.550000    0.354839\n",
      "Running Nussinov on 200 sequences from bpRNA-NF-15.0...\n",
      "  Done 20/200\n",
      "  Done 40/200\n",
      "  Done 60/200\n",
      "  Done 80/200\n",
      "  Done 100/200\n",
      "  Done 120/200\n",
      "  Done 140/200\n",
      "  Done 160/200\n",
      "  Done 180/200\n",
      "  Done 200/200\n",
      "\n",
      "bpRNA-NF-15.0 Nussinov summary:\n",
      "        Precision      Recall          F1\n",
      "count  200.000000  200.000000  200.000000\n",
      "mean     0.037279    0.074482    0.048184\n",
      "std      0.079876    0.134916    0.095539\n",
      "min      0.000000    0.000000    0.000000\n",
      "25%      0.000000    0.000000    0.000000\n",
      "50%      0.000000    0.000000    0.000000\n",
      "75%      0.041754    0.119485    0.061080\n",
      "max      0.605263    0.638889    0.621622\n"
     ]
    }
   ],
   "source": [
    "# Nussinov evaluation on ArchiveII eval subset\n",
    "arch_nussinov_df = run_nussinov_eval_on_subset(arch_eval_subset, name=\"ArchiveII\")\n",
    "\n",
    "# Nussinov evaluation on bpRNA eval subset\n",
    "bprna_nussinov_df = run_nussinov_eval_on_subset(bprna_eval_subset, name=\"bpRNA-NF-15.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6eed53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Nussinov evaluation CSVs in ..\\results\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path(\"../results\")\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "arch_nussinov_df.to_csv(results_dir / \"archiveII_nussinov_eval.csv\", index=False)\n",
    "bprna_nussinov_df.to_csv(results_dir / \"bprna_nussinov_eval.csv\", index=False)\n",
    "\n",
    "print(\"Saved Nussinov evaluation CSVs in\", results_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a688b30",
   "metadata": {},
   "source": [
    "## 6. Nussinov Baseline Run for ArchiveII\n",
    "\n",
    "We implement:\n",
    "\n",
    "- Dataset split into training, test and validation for ArchiveII dataset\n",
    "- Run the baseline for the split sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9edb47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "archiveii_csv_path = archiveii_csv_path  # from earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3ff4cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full ArchiveII size: 3975\n",
      "Train size: 2782\n",
      "Test size: 1193\n",
      "Saved:\n",
      "   c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\archiveII\\processed\\archiveII_train.csv\n",
      "   c:\\Fall_2025\\CSE6301\\Project\\rna-structural-prediction\\data\\archiveII\\processed\\archiveII_test.csv\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Create ArchiveII 70/30 Train–Test Split\n",
    "# -----------------------------\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load full ArchiveII dataset\n",
    "full_df = pd.read_csv(archiveii_csv_path)\n",
    "print(\"Full ArchiveII size:\", len(full_df))\n",
    "\n",
    "# 70% train, 30% test\n",
    "train_df, test_df = train_test_split(\n",
    "    full_df, test_size=0.30, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_df))\n",
    "print(\"Test size:\", len(test_df))\n",
    "\n",
    "# Where to save (same directory as archiveII_from_bpseq.csv)\n",
    "processed_dir = Path(archiveii_csv_path).parent\n",
    "\n",
    "archive_train_csv = processed_dir / \"archiveII_train.csv\"\n",
    "archive_test_csv  = processed_dir / \"archiveII_test.csv\"\n",
    "\n",
    "train_df.to_csv(archive_train_csv, index=False)\n",
    "test_df.to_csv(archive_test_csv, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", archive_train_csv)\n",
    "print(\"  \", archive_test_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a3a8599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 2782\n",
      "Val dataset size: 357\n",
      "Test dataset size: 836\n",
      "Train batch shapes: torch.Size([8, 364]) torch.Size([8, 364]) torch.Size([8, 364, 364])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Datasets for each split\n",
    "arch_train_dataset = ArchiveIIDataset(str(archive_train_csv))\n",
    "arch_val_dataset   = ArchiveIIDataset(str(archive_val_csv))\n",
    "arch_test_dataset  = ArchiveIIDataset(str(archive_test_csv))\n",
    "\n",
    "print(\"Train dataset size:\", len(arch_train_dataset))\n",
    "print(\"Val dataset size:\", len(arch_val_dataset))\n",
    "print(\"Test dataset size:\", len(arch_test_dataset))\n",
    "\n",
    "# DataLoaders (models will see the FULL splits, not a subset)\n",
    "train_loader = DataLoader(\n",
    "    arch_train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_rna_batch,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    arch_val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_rna_batch,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    arch_test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_rna_batch,\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "input_ids, mask, targets = batch\n",
    "print(\"Train batch shapes:\", input_ids.shape, mask.shape, targets.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rna-bench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
